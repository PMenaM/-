{"cells":[{"cell_type":"markdown","id":"6918e18a-c248-4929-b552-7aee2057c0eb","metadata":{},"source":["За последние несколько лет онлайн-покупки быстро развиваются, делая нашу жизнь проще. Но за кулисами компании e-commerce сталкиваются со сложной проблемой.\n","\n","Неопределенность играет большую роль в том, как цепочки поставок планируют и организуют свои операции, чтобы гарантировать своевременную доставку продукции. Эта неопределенность может привести к таким проблемам, как дефицит, задержки поставок и увеличение эксплуатационных расходов.\n","\n","Компания e-commerce требовалась помощь в планировании предстоящих продаж на конец года. Они хотели спланировать рекламные возможности и управлять своими запасами. Целью этих усилий является обеспечение наличия на складе нужных продуктов, когда это необходимо, и обеспечение того, чтобы их клиенты были удовлетворены быстрой доставкой.\n","\n","\n","## Данные:\n","\n","Краткое изложение датасета о продажах:\n","\n","# Online Retail.csv\n","\n","| Столбец     | Описание              |\n","|------------|--------------------------|\n","| `'InvoiceNo'` | 6-значный уникальный номер для каждой транзакции |\n","| `'StockCode'` | Уникальный пятизначный номер для каждого отдельного продукта |\n","| `'Description'` | Название продукта |\n","| `'Quantity'` | Количество каждого товара за транзакцию |\n","| `'UnitPrice'` | Цена продукта за единицу |\n","| `'CustomerID'` | 5-значный уникальный номер для каждого клиента |\n","| `'Country'` | Название страны, в которой проживает каждый клиент |\n","| `'InvoiceDate'` | День и время создания каждой транзакции `\"ММ/ДД/ГГГГ\"` |\n","| `'Year'` | Год, когда была создана каждая транзакция |\n","| `'Month'` | Месяц, в котором была создана каждая транзакция |\n","| `'Week'` | Неделя, когда была создана каждая транзакция (`1`-`52`) |\n","| `'Day'` | День месяца, когда была создана каждая транзакция (`1`-`31`) |\n","| `'DayOfWeek'` | День недели, когда была сгенерирована каждая транзакция <br>(`0` = Понедельник, `6` = Воскресенье) |"]},{"cell_type":"code","execution_count":null,"id":"b5106e04-f9da-459f-a1cc-14e437fe001d","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":29720,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1709557827711,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Insert the code necessary to solve the assigned problems. Use as many code cells as you need.\n# Import required libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.sql.functions import col, dayofmonth, month, year,  to_date, to_timestamp, weekofyear, dayofweek\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n# Initialize Spark session\nmy_spark = SparkSession.builder.appName(\"SalesForecast\").getOrCreate()\n\n# Importing sales data\nsales_data = my_spark.read.csv(\n    \"Online Retail.csv\", header=True, inferSchema=True, sep=\",\")\n\n# Convert InvoiceDate to datetime \nsales_data = sales_data.withColumn(\"InvoiceDate\", to_date(\n    to_timestamp(col(\"InvoiceDate\"), \"d/M/yyyy H:mm\")))\n\n# Aggregate data into daily intervals\ndaily_sales_data = sales_data.groupBy(\"Country\", \"StockCode\", \"InvoiceDate\", \"Year\", \"Month\", \"Day\", \"Week\", \"DayOfWeek\").agg({\"Quantity\": \"sum\", \"UnitPrice\": \"avg\"})\n\n# Rename the target column\ndaily_sales_data = daily_sales_data.withColumnRenamed(\n    \"sum(Quantity)\", \"Quantity\")\n\n# Split the data into two sets based on the spliting date, \"2011-09-25\". All data up to and including this date should be in the training set, while data after this date should be in the testing set. Return a pandas Dataframe, pd_daily_train_data, containing, at least, the columns [\"Country\", \"StockCode\", \"InvoiceDate\", \"Quantity\"].\n\nsplit_date_train_test = \"2011-09-25\"\n\n# Creating the train and test datasets\ntrain_data = daily_sales_data.filter(\n    col(\"InvoiceDate\") <= split_date_train_test)\ntest_data = daily_sales_data.filter(col(\"InvoiceDate\") > split_date_train_test)\n\npd_daily_train_data = train_data.toPandas()\n\n# Creating indexer for categorical columns\ncountry_indexer = StringIndexer(\n    inputCol=\"Country\", outputCol=\"CountryIndex\").setHandleInvalid(\"keep\")\nstock_code_indexer = StringIndexer(\n    inputCol=\"StockCode\", outputCol=\"StockCodeIndex\").setHandleInvalid(\"keep\")\n\n# Selectiong features columns\nfeature_cols = [\"CountryIndex\", \"StockCodeIndex\", \"Month\", \"Year\",\n                \"DayOfWeek\", \"Day\", \"Week\"]\n\n# Using vector assembler to combine features\nassembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n\n# Initializing a Random Forest model\nrf = RandomForestRegressor(\n    featuresCol=\"features\",\n    labelCol=\"Quantity\",\n    maxBins=4000\n)\n\n# Create a pipeline for staging the processes\npipeline = Pipeline(stages=[country_indexer, stock_code_indexer, assembler, rf])\n\n# Training the model\nmodel = pipeline.fit(train_data)\n\n# Getting test predictions\ntest_predictions = model.transform(test_data)\ntest_predictions = test_predictions.withColumn(\n    \"prediction\", col(\"prediction\").cast(\"double\"))\n\n# Provide the Mean Absolute Error (MAE) for your forecast? Return a double/floar \"mae\"\n\n# Initializing the evaluator\nmae_evaluator = RegressionEvaluator(\n    labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"mae\")\n\n# Obtaining MAE\nmae = mae_evaluator.evaluate(test_predictions)\n\n# How many units will be sold during the  week 39 of 2011? Return an integer `quantity_sold_w39`.\n\n# Getting the weekly sales of all countries\nweekly_test_predictions = test_predictions.groupBy(\"Year\", \"Week\").agg({\"prediction\": \"sum\"})\n\n# Finding the quantity sold on the 39 week. \npromotion_week = weekly_test_predictions.filter(col('Week')==39)\n\n# Storing prediction as quantity_sold_w30\nquantity_sold_w39 = int(promotion_week.select(\"sum(prediction)\").collect()[0][0])\n\n# Stop the Spark session\nmy_spark.stop()","outputsMetadata":{"0":{"height":37,"type":"stream"},"1":{"height":57,"type":"stream"},"2":{"height":37,"type":"stream"},"3":{"height":37,"type":"stream"},"4":{"height":37,"type":"stream"}}},"outputs":[],"source":["# Импорт необходимых библиотек\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml import Pipeline\n","from pyspark.ml.regression import RandomForestRegressor\n","from pyspark.sql.functions import col, dayofmonth, month, year,  to_date, to_timestamp, weekofyear, dayofweek\n","from pyspark.ml.feature import StringIndexer\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","# Инициализация сеанса Spark\n","my_spark = SparkSession.builder.appName(\"SalesForecast\").getOrCreate()\n","\n","# Импорт данных о продажах\n","sales_data = my_spark.read.csv(\"Online Retail.csv\", header=True, inferSchema=True, sep=\",\")\n","\n","# Преобразование 'InvoiceDate' в формат временного ряда\n","sales_data = sales_data.withColumn(\"InvoiceDate\", to_date(to_timestamp(col(\"InvoiceDate\"), \"d/M/yyyy H:mm\")))\n","\n","# Агрегация данных по суточным интервалам\n","daily_sales_data = sales_data.groupBy(\"Country\", \"StockCode\", \"InvoiceDate\", \"Year\", \"Month\", \"Day\", \"Week\", \"DayOfWeek\").agg({\"Quantity\": \"sum\", \"UnitPrice\": \"avg\"})\n","\n","# Переименование целевого столбца\n","daily_sales_data = daily_sales_data.withColumnRenamed(\"sum(Quantity)\", \"Quantity\")\n","\n","# Разделение данных на два набора на основе даты разделения \"2011-09-25\" (<= для обучения, > для тестирования).\n","# Возврат Dataframe, 'pd_daily_train_data', содержащего столбцы [\"Country\", \"StockCode\", \"InvoiceDate\", \"Quantity\"].\n","split_date_train_test = \"2011-09-25\"\n","\n","# Создание обучающих и тестовых наборов\n","train_data = daily_sales_data.filter(col(\"InvoiceDate\") <= split_date_train_test)\n","test_data = daily_sales_data.filter(col(\"InvoiceDate\") > split_date_train_test)\n","\n","pd_daily_train_data = train_data.toPandas()\n","\n","# Создание индексатора для категориальных столбцов\n","country_indexer = StringIndexer(inputCol=\"Country\", outputCol=\"CountryIndex\").setHandleInvalid(\"keep\")\n","stock_code_indexer = StringIndexer(inputCol=\"StockCode\", outputCol=\"StockCodeIndex\").setHandleInvalid(\"keep\")\n","\n","# Выбор столбцов функций\n","feature_cols = [\"CountryIndex\", \"StockCodeIndex\", \"Month\", \"Year\", \"DayOfWeek\", \"Day\", \"Week\"]\n","\n","# Использование векторного ассемблера для объединения функций\n","assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n","\n","# Инициализация модели Random Forest\n","rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"Quantity\", maxBins=4000)\n","\n","# Создание пайплайн для постановки процессов\n","pipeline = Pipeline(stages=[country_indexer, stock_code_indexer, assembler, rf])\n","\n","# Обучение модели\n","model = pipeline.fit(train_data)\n","\n","# Получение тестовых прогнозов и назначение их новому столбцу\n","test_predictions = model.transform(test_data)\n","test_predictions = test_predictions.withColumn(\"prediction\", col(\"prediction\").cast(\"double\"))\n","\n","# Инициализация оценщика регрессии\n","mae_evaluator = RegressionEvaluator(labelCol=\"Quantity\", predictionCol=\"prediction\", metricName=\"mae\")\n","\n","# Получение средней абсолютной ошибки (MAE)\n","mae = mae_evaluator.evaluate(test_predictions)\n","\n","# Вопрос: Сколько единиц будет продано на 39-й неделе 2011 года? Возврат целого числа 'quantity_sold_w39'\n","# Получение еженедельных продаж всех стран\n","weekly_test_predictions = test_predictions.groupBy(\"Year\", \"Week\").agg({\"prediction\": \"sum\"})\n","\n","# Нахождение количества проданного товара на 39 неделе \n","promotion_week = weekly_test_predictions.filter(col('Week')==39)\n","\n","# Сохранение прогноза как 'quantity_sold_w30'\n","quantity_sold_w39 = int(promotion_week.select(\"sum(prediction)\").collect()[0][0])\n","\n","# Остановка сеанса Spark\n","my_spark.stop()"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
